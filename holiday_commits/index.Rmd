---
title: "Curiosity and Play"
author: "Yim Register"
date: "7/2/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(kableExtra)
```

## Curiosity killed the cat, but satisfaction brought it back

Sometimes, some of the most intricate problems arise from simple musings among friends. This is one of the beautiful things about problem solving, programming, and statistics. When you are curious enough and excited about a problem, you may find yourself exploring every caveat just to prove your point! (*Be careful though, don't forgo sleep. We cover the detrimental effects of missing sleep on your coding performance in another lesson!*) While it is very important to tackle real problems that are genuinely affecting people's lives, first we have to learn to wrangle statistics and ask the right kinds of questions. Learning this skill will help you to ask critical questions when it really counts, like when building software for hospitals, news sites, financial institutions, or maybe the next rocket to Mars. One of the best ways to teach these skills is to lock on to a personally meaningful, but low-stakes, question; **and answer it**.

## Playing with Data

In this lesson, you will learn to meaningfully play with data. So often in our academic careers we are expected to perfectly follow along and do things the "right" way, in order to build our skills to become an essential and productive member of a team/company/society. We can get through our math classes by "plugging-it-in" to equations, get through English by practicing flash cards, and get through History by memorizing dates. But we can gain a lot through creatively expressing ourselves in our learning. So this lesson will demonstrate how to make queries to archived GitHub data, generate plots of interest, and answer our own curiosities (sometimes frivolous, but who cares?!) You will have several chances to creatively express yourself in this lesson, while still being guided by examples.



## GHTorrent and BigRQuery
We need to begin by getting **data**. Luckily [the GHTorrent project](http://ghtorrent.org) has been archiving data from the GitHub API for the past several years, and we can get access to *commits, users, forks, repos, locations* and more. While there are several ways to load this data into R, we are going to rely on `bigrquery` to interface with Google BigQuery and the public GHTorrent data on the Google Cloud. Here are the steps you need to take:

* Set up an account with [Google Cloud](https://cloud.google.com/). They do require a credit card number, which is ridiculous. But they will *not* auto-charge you when your free trial is up.
* Create a project from the Google Cloud console. Name it using something you'd like to use to access the project with `bigrquery`
* Make sure to enable the BigQuery API for the project. Go to the APIs & Services card on the console, and navigate to "Enable APIs and Services" where you can search for 'BigQuery' and enable it.
* You will be able to test out SQL queries on [here](https://bigquery.cloud.google.com)
* The GHTorrent project for BigQuery is located [here](https://bigquery.cloud.google.com/dataset/ghtorrent-bq:ght), with a small tutorial [here](http://ghtorrent.org/gcloud.html)

The next piece of this is to not only understand that the data is being held on the Google Cloud (that we can access with SQL queries), but to understand how we can do that from our local machines, in R. We will use the [`bigrquery`](https://www.rdocumentation.org/packages/bigrquery/versions/0.4.1) package, with a tutorial [here](https://cloud.google.com/blog/products/gcp/google-cloud-platform-for-data-scientists-using-r-with-google-bigquery). `bigrquery` allows us to link our R code to our project on the cloud. You will be asked to authenticate.

```{r}
library(bigrquery)
library(ggplot2)
bq_auth(path="../../servicetoken.json") # you will need to get your own service token from your account. Don't share this!
project <- "gitstats" #your project name here
```

## Alan Turing's Birthday Examples (learn some SQL queries)

Here are some examples for using `bigrquery` to access GHTorrent data. Here, we take a look at Alan Turing's birthday (June 23) for the year 2016.This should help you get the hang of some SQL commands and collecting data. I chose [Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing) because I'm an Artificial Intelligence nerd, and once even had a hamster named Turing. You can plug in your own birthday, or the birthday of someone else you admire. The point is to start playing.

There is a lot to unpack in your first SQL command. Here's a small recipe for reading the examples:

- the first line indicates what columns will come out in the final dataframe (`select  p.language as language, count(c.id) as num_commits`)
- `WHERE` is similar to `if` logic, and it grabs anything that fits the specified condition
- in the following example, we care about anything in the ghtorrent database `WHERE date(created_at) = date('2016-06-23))`
- that means that the commit data from ghtorrent has a `created_at` property, and we want data from where that date equals Alan Turing's birthday in 2016
- the `language` property of those commits to GitHub are stored in the ghtorrent-bq.ght.projects database, and we want to report all the languages used on the day we selected, except for if the `language` property is `null` because that's not helpful to us (unless you care about that)
- we `group_by` language, meaning that we want to see the number of commits for each language *separately*. We are going to compare the different languages and their relative number of commits on this day.
- and finally, we order everything in the data by the number of commits, in *descending order*. We want to see the *most* commits first. 
- Do you have any predictions for which language was the most committed to?



```{r}
# walking through an SQL example
# languge with most commits on Alan Turing's birthday in 2016 
sql_birthday <- "SELECT  p.language as language, count(c.id) as num_commits
from [ghtorrent-bq.ght.project_commits] pc join
     (SELECT id, author_id, created_at FROM [ghtorrent-bq.ght.commits] WHERE
     date(created_at) = date('2016-06-23') )c on pc.commit_id = c.id join
     (SELECT id, language, description
     FROM [ghtorrent-bq.ght.projects] WHERE language != 'null')p on p.id = pc.project_id join
     (SELECT login,  id
     FROM [ghtorrent-bq.ght.users]) u on c.author_id = u.id,
group by language
order by num_commits desc;"
```

## Execute the query
We use `query_exec` to execute the query with `bigrquery` to the ghtorrent database, hosted on BigQuery. We get back a dataframe, stored in `bday_commits`.
```{r}
bday_commits  <- query_exec(sql_birthday, project = project, useLegacySql = FALSE) #remember we defined 'project' up above

kable(head(bday_commits)) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

## Visualize the Data
The following is a `ggplot` of the top 7 languages used on Alan Turing's birthday, by number of commits to each. 

- `bday_commits[1:7,]` selects the first 7 rows in the dataframe
- `aes()` is the "aesthetic": what is the x and y that you are plotting?
- `fill = language` is simply how we get the pretty colors to show up
- `geom_bar` indicates that we want a bar plot. We could also use `geom_point()` for a scatter plot
- `stat="identity"` indicates that the bar plot should use the raw value of num_commits instead of a different statistical transformation
- `xlab`,`ylab`,and `ggtitle` are the x-axis label, y-axis label, and title, respectively
` `theme_bw()` is "Theme Black and White" and I just like it better

```{r}
plt = ggplot(bday_commits[1:7,],aes(language,num_commits,fill=language))+
  geom_bar(stat="identity")+
  xlab("Language")+
  ylab("Number of Commits")+
  ggtitle("GitHub Commits by Language on Alan Turing's Birthday")+
  theme_bw()
plt
ggsave("bdaycommits.png",plt)
 
```



#### I can't imagine that Alan Turing would have been the biggest JavaScript fan. Let's take a look at projects where the project description includes "AI". Here, we see Python emerge as top commits for the day.

```{r}
# languge with most commits on Alan Turing's birthday in 2016 

sql_example2 <- "SELECT p.description as description, p.language as language, count(c.id) as num_commits
from [ghtorrent-bq.ght.project_commits] pc join
     (SELECT id, author_id, created_at FROM [ghtorrent-bq.ght.commits] WHERE
     date(created_at) = date('2016-06-23') )c on pc.commit_id = c.id join
     (SELECT id, language, description
     FROM [ghtorrent-bq.ght.projects] WHERE language != 'null' and description LIKE '%AI%')p on p.id = pc.project_id join
     (SELECT login,  id
     FROM [ghtorrent-bq.ght.users]) u on c.author_id = u.id,
group by description,language
order by num_commits desc;"

example2  <- query_exec(sql_example2, project = project, useLegacySql = FALSE)

plt = ggplot(example2[1:6,],aes(language,num_commits,fill=language))+
  geom_bar(stat="identity")+
  ggtitle("Commits to 'AI' Projects on Alan Turing's Birthday",subtitle="Who would even want to know this?")+
  theme_bw()
plt

python_desc <- example2[example2$language=='Python',]
python_desc <- python_desc[order(-python_desc$num_commits),]


kable(python_desc[1:10,])%>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Language Growth over Time
Let's investigate another question. Do you know anyone who is obsessed with a certain language? Maybe they can't stop talking about how Julia is gonna rule the world, or how Golang is the future because of all that multithreading (I've never used Golang). Or maybe you're a straight up *fan* of some language and you want to make sure that other people know how awesome it is (Scala, anyone?) This is a fun exercise in seeing how languages grow over time, by the number of commits for those projects on GitHub.
In this example:

- we `SELECT` language, day, and num_commits to make a dataframe where we can monitor commits over time for different languages
- we use  `WHERE language == 'Python'` to select all projects where the language is Python
- the `||` syntax indicates a logical OR symbol. We are collecting Python *or* Scale *or* Julia *or* Ruby... *or* whatever else you'd like to plug in.
- We `group_by(language,day)` to get the number of commits, by language, by day, over time. 
- And finally, we order the data by the greatest number of commits first

```{r}
language_sql <- "SELECT  p.language as language, date(created_at) as day,count(c.id) as num_commits
from [ghtorrent-bq.ght.project_commits] pc join
     (SELECT id, author_id, created_at FROM [ghtorrent-bq.ght.commits] WHERE
     date(created_at) between date('2012-01-01')
                          and  date('2016-09-05') )c on pc.commit_id = c.id join
     (SELECT id, language, description
     FROM [ghtorrent-bq.ght.projects] WHERE language == 'Scala' || language == 'Python' || language == 'Julia' || language=='Ruby')p on p.id = pc.project_id join
     (SELECT login,  id
     FROM [ghtorrent-bq.ght.users]) u on c.author_id = u.id,
group by language,day
order by num_commits desc;"


lang_growth  <- query_exec(language_sql, project = project, useLegacySql = FALSE)

kable(head(lang_growth))%>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```
### Cumulative Sum
We take the cumulative sum over time to indicate *total* commits over time, as opposed to commits on that particular day.
```{r}
lang_growth <-lang_growth[order(lang_growth$day),]
lang_growth$n <-seq.int(nrow(lang_growth))
lang_growth$csum <- ave(lang_growth$num_commits, lang_growth$language, FUN=cumsum)
lang_growth <- lang_growth %>%
  group_by(language) %>%
  mutate(sum_commits = cumsum(num_commits))

plt = ggplot(lang_growth,aes(n,csum,color=language))+
  geom_line()+
  theme_bw()+
  ylab("Number of Commits")+
  xlab("Time (days)")+
  ggtitle("Commits over time")+
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
plt
ggsave("commits.png",plt)


```



## Commits to GitHub: Canada Day vs. July 4th
Alright, now that we have explored how to use `bigrquery` and generate some simple queries and plots, let's get back to our Canada vs. USA comparison. The queries will get more complex as we continue to explore, and refine what we want to know. You may be developing an intuition for what you believe to be true; of course people don't commit on a holiday! They're not working! But what about the case where company repos are kept private, and the data that GHTorrent has access to is actually "for fun" repos, and a day off is the perfect day for that programmer to keep making their alien game. Intuition is certainly important when asking statistical questions, as it guides us towards different factors to account for and questions to ask. But remember, your intuition may be the exact opposite of someone else's.

### Total Commits

We start by taking a look at the total commits to GitHub on either Canada Day or Independence Day, from either Canada or the United States. We immediately discover that raw count is *not* going to be helpful in making any meaningful comparsions. The US has orders of magnitude more commits on any given day than Canada does. While that is good to know, we need to account for it if we actually want to make comparisons.
```{r}
data_sql <- "select  u.country_code as country, date(c.created_at) as day, count(c.id) as num_commits
from [ghtorrent-bq.ght.project_commits] pc join
     (SELECT id, author_id, created_at FROM [ghtorrent-bq.ght.commits] WHERE
     date(created_at) = date('2016-07-01')
                          or date(created_at)= date('2016-07-04') )c on pc.commit_id = c.id join
     (SELECT id,
     FROM [ghtorrent-bq.ght.projects]) p on p.id = pc.project_id join
     (SELECT login, location, id, country_code,
     FROM [ghtorrent-bq.ght.users]
     WHERE country_code = 'us' or country_code = 'ca') u on c.author_id = u.id,
group by country, day
order by num_commits desc;"

total_commits  <- query_exec(data_sql, project = project, useLegacySql = FALSE)

kable(total_commits)%>%
  kable_styling(bootstrap_options = c("striped", "hover"))

plt = ggplot(total_commits, aes(day,num_commits,fill=country))+
  geom_bar(stat="identity",position="dodge")+
  ggtitle("Number of Holiday Commits (Canada v. USA)")+
  theme_bw()
plt

```

### Relative Commits
What we actually need to care about is, *on average* do number of commits differ on a holiday? In order to do that, let's look at number of commits per day across a year sample, between Canada and USA. Next, we will compute the **z-score** for each day, comparing each day's number of commits to how it deviates from the number of commits on average.
```{r fig.width=13,fig.height=4}
data_sql <- "select  u.country_code as country, date(c.created_at) as day, count(c.id) as num_commits
from [ghtorrent-bq.ght.project_commits] pc join
     (SELECT id, author_id, created_at FROM [ghtorrent-bq.ght.commits] WHERE
     date(created_at) between date('2016-01-01')
                          and  date('2016-09-05') )c on pc.commit_id = c.id join
     (SELECT id,
     FROM [ghtorrent-bq.ght.projects]) p on p.id = pc.project_id join
     (SELECT login, location, id, country_code,
     FROM [ghtorrent-bq.ght.users]
     WHERE country_code = 'us' or country_code = 'ca') u on c.author_id = u.id,
group by country, day
order by num_commits desc;"

year_commits  <- query_exec(data_sql, project = project, useLegacySql = FALSE)

plt = ggplot(year_commits,aes(day,num_commits,colour=country))+
  geom_line(aes(group=country))+
  theme_bw()+
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank())+
  ggtitle("2016 Commits on GitHub (Canada vs. USA)", subtitle="January 1 - September 5")
plt
```


```{r, message=FALSE}
#let's do some important checks on outliers
bp <- boxplot(year_commits$num_commits ~ year_commits$country)
year_commits <- year_commits[!(year_commits$num_commits %in% bp$out),]
bp <- boxplot(year_commits$num_commits ~ year_commits$country)

library(plyr)
library(dplyr)
summary <- year_commits %>% 
  group_by(country) %>%
  summarise(avg = mean(num_commits),sd=sd(num_commits))

kable(summary)%>%
  kable_styling(bootstrap_options = c("striped", "hover"))

head(year_commits)

#TODO group by country and z scale each and then plot by day


```

```{r}
scaled <-ddply(year_commits,c("country"),transform,scaled_commits = scale(num_commits))
#am I even allowed to do this if it's not normal?
head(scaled)

#notice how now they overlap. We predicted that, because there's no real reason that Canada should be all that different from USA. We do see some differences, but this could also be due to the fact that Canada has less users/commits overall

# you can see that they both have weekends pretty clearly
scaled$weekday <- weekdays(as.Date(scaled$day))

#it's not normal so we can't really use scaled for anything
hist(year_commits$num_commits)


plt = ggplot(scaled,aes(day,scaled_commits,colour=country))+
  geom_line(aes(group=country))+
  theme_bw()+
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank())+
  ggtitle("2016 SCALED Commits on GitHub (Canada vs. USA)", subtitle="January 1 - September 5")
plt
```
### Testing for normality (nothing is normal)


### Is a holiday really any different from any other weekday?
```{r fig.height=3}
# usa vs. canada
wilcox.test(scaled$scaled_commits[year_commits$country=='ca'],scaled$scaled_commits[year_commits$country=='us'])
scaled$isWeekend <- 0
scaled$isWeekend[scaled$weekday=='Saturday'|scaled$weekday=='Sunday']<-1
#let's test our sanity?

ggplot(scaled[scaled$isWeekend==1,], aes(x=num_commits,fill=country))+
  geom_histogram()+
  facet_wrap(~country)+
  scale_x_continuous(labels = function(x) format(x, scientific = FALSE))+
  theme_bw()
  
ggplot(scaled[scaled$isWeekend==0,], aes(x=num_commits,fill=country))+
  geom_histogram()+
  facet_wrap(~country)+
  scale_x_continuous(labels = function(x) format(x, scientific = FALSE))+
  theme_bw()


#not normal
ddply(scaled,c('country','isWeekend'),summarise,mean = mean(num_commits),sd(num_commits))
```

### Logistic regression for predicting your weekend commits

```{r}

#is the holiday really any different from any other weekday?
plot(scaled$num_commits,scaled$isWeekend) # plot with body size on x-axis and survival (0 or 1) on y-axis
logistic <- glm(scaled$isWeekend ~ scaled$num_commits, family = "binomial")



vals <- predict(logistic,data.frame(x=scaled$num_commits),type="resp") # draws a curve based on prediction from logistic regression model
plt <- ggplot(aes(num_commits,isWeekend),data=scaled)+
  geom_point(size=1)+
  geom_line(aes(num_commits,vals),color="#8DD3C7",size=1)+
  theme_bw()+
  scale_x_continuous(labels = function(x) format(x, scientific = FALSE))
plt
# there is a true difference
#canada day



```





