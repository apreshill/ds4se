---
title: "Analyze This!"
author: "Yim Register"
date: "8/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(ggplot2)
```


## What is "Evidence"?

You're about to learn a term that hopefully won't haunt you like it haunted me: *epistemology*. I recently spent an entire year using the term *epistemology* to the point of irony, after having it repeated over and over in my first-year PhD courses. Epistemology is the study of knowing. I won't go too far into this, as it's literally PhDs worth of studying, but it's "how we know what we think we know".

>the theory of knowledge, especially with regard to its methods, validity, and scope. Epistemology is the investigation of what distinguishes justified belief from opinion

Miraculously, we can go through years of school and never question how we know anything. We learn from history books, practice math formulas, create artwork, and maybe conduct some neat experiments. All of that knowledge had to come from *somewhere*, and some of it is wrong.

Part of being a digital citizen, software engineer, and scholar is learning how to defend what you think you know. Whether that's in political arguments or convincing someone why pickles are a polarized issue, you will be caught over and over again in some form of argumentation. In software engineering, there are opinions abound! On the best language, best practice, hottest new package, best workflow, etc.

Through these lessons, you will develop your own ability to question how we know what we know; walking through how we can use data and statistics to make conclusions about the software industry. Some people believe that statistics are the ground truth, while others believe that numbers could never capture the nuance of a problem. Both of these views are dangerous. We are about to embark on a journey into Statistical Wonderland, where some things are nonsense, some things are useful, some things are wrong, and some things are awesome. The goal of this curriculum is to give you a toolbox to find your *own* answers; to learn to read and dissect academic findings and to apply the useful results to your own practice of software engineering.


## Surveying a Population

Sometimes we don't know anything about anything. We all have to start somewhere. The following paper, *[Analyze This!](http://delivery.acm.org/10.1145/2570000/2568233/p12-begel.pdf?ip=97.113.215.117&id=2568233&acc=ACTIVE%20SERVICE&key=B63ACEF81C6334F5%2EF43F328D6C8418D0%2E90053D5C35FBAB49%2E4D4702B0C3E38B35&__acm__=1565042855_5bb53d7b3013f10739251d27178d0bb7) approaches an unexplored research area with a certain elegance. They asked 1500 Microsoft engineers the following:

>Please list up to five questions you would like [a team of data scientists who specialize in studying how software is developed] to answer

They then asked a new sample of 2500 Microsoft engineers to prioritize the questions.

So yeah, they just *asked*. If you want to know what the most important things that Data Scientists should work on, *just ask*. This is an incredible, high-powered starting point for distilling how we should investigate what is most important to the stakeholders involved. Let's take a look at how this sample prioritized things, while also getting a lesson in R.

### Reading in the Data
Here we have an excel sheet, but many data files will be Comma Separated Values `(.csv)`. We are using the `readxl` library to convert the excel sheet into a `dataframe` that R can work with. 

```{r}
data <- read_excel("../bin/data/145Questions.xlsx",skip=3) #skip the first three rows because they have some copywrite stuff from Microsoft that reads in a little weird
#read.csv("path/here.csv")
```

### Renaming Columns
The columns had names that weren't as condusive to the code we will write, so here's how to rename columns in a dataframe. You do need to include all of the names using this technique.
```{r}
colnames(data) <- c("QuestionID","Category","Question","Essential",  "Worthwhile"  ,     "Unimportant" , "Unwise","Don't Know" , "Distribution",  "EssentialPercent" ,  "WorthwhilePercent" ,"UnwisePercent" ,     "EssentialRank"  , "WorthwhileRank", "UnwiseRank")
```

### Descriptive Statistics
Whenever we have data, we first report on descriptive statistics. *Descriptive* statistics are things like the average values, the ranges of those values (highest and lowest), and other facts about the data that was collected. Descriptive statistics are contrasted with *inferential* statistics, which use statistical tests to draw conclusions about differences between groups, or fits of models, or other things that we can use to make sense of various phenomena. Let's stick with descriptive statistics for now.


### First Visualization

We are going to make some boxplots. You may or may not have learned about "Box-and-Whisker Plots" before. There are several pieces to these plots that help us visualize descriptive statistics. The bar in the middle of the box is the **mean**, and any points outside of the box-and-whisker plot are **outliers** (meaning they are significantly above or below the **interquartile range**.) We can't actually know too much from these plots, as they simply show us, *across all categories*, how willing the participants were to assign a certain label to a Question. We can observe that people seemed more willing to label something as "Worthwhile" than they did "Unwise" or "Essential". This actually makes sense, because it's easier to label something with a less-extreme judgment. "Unwise" is seriously suggesting that something should not be done, and "Essential" is making a serious judgment call on the value of something. "Worthwhile" is more relaxed, and it seems that more people were willing to use that label instead of strongly committing on most of the topics. It's lucky for us that everything wasn't labeled "Essential" or we wouldn't even have a better idea of where to start researching!

* Note: I'm using something called `ggplot` and `cowplot` to make these graphs. `ggplot` is a cornerstone of data visualization, whereas `cowplot` simply allows me to line them up horizontally. I've used `theme(axis.text.x=element_blank()` to remove the x-axis labels. I use `theme_bw()` which stands for "Theme Black and White" because it looks better to me. You should play around with your own preferences! 
```{r fig.width=10}

essential <- ggplot(data,aes(y=Essential,))+
  geom_boxplot()+
  theme_bw()+
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

worthwhile <- ggplot(data,aes(y=Worthwhile))+
  geom_boxplot()+
  theme_bw()+
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

unimportant <- ggplot(data,aes(y=Unimportant))+
  geom_boxplot()+
  theme_bw()+
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

unwise <- ggplot(data,aes(y=Unwise))+
  geom_boxplot()+
  theme_bw()+
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

cowplot::plot_grid(essential, worthwhile, unimportant,unwise ,
                   ncol = 4, rel_heights = c(1, 1),
                   align = 'h', axis = 'lr')

```

### Distribution Across Questions

```{r}

#what I want is, across the different categories, how much was labeled Essential, Worthwhile, Unimportant, Unwise

#idk what the hell I'm trying to show here
ggplot(data,aes())+
  geom_density(aes(Essential,fill="Essential"),alpha=.5)+
  geom_density(aes(Worthwhile,fill="Worthwhile"),alpha=.5)+
  geom_density(aes(Unimportant,fill="Unimportant"),alpha=.5)+
  geom_density(aes(Unwise,fill="Unwise"),alpha=.5,)+
  xlab("Distributed Priority Percentage Across Questions")+
  theme_bw()
```

### Most Essential Question
```{r fig.width=10}
ggplot(data,aes(QuestionID,Essential,fill=Category))+
  geom_bar(stat="identity")+
  theme_bw()


#this R syntax is grabbing the Question cell wherever the Essential value is matching the maximum Essential value. Let's see what was considered Essential by the most people!
data$Question[data$Essential==max(data$Essential)]
```

### Most Unwise Question
```{r fig.width=10}
ggplot(data,aes(QuestionID,Unwise,fill=Category))+
  geom_bar(stat="identity")+
  theme_bw()


data$Question[data$Unwise==max(data$Unwise)]
```

## Reading Academic Papers
## Qualitative and Quantitative Methods


## Statistics Refresher and R Basics

## Measuring "Essential"


```{r}


ggplot(data,aes(Category,Essential,color=Category))+
  stat_summary(fun.data=mean_cl_boot)+
  ggtitle("Essential")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(data,aes(Category,Worthwhile,color=Category))+
  stat_summary(fun.data=mean_cl_boot)+
  ggtitle("Worthwhile")+
  
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

## Don't Measure Dev Practices

It's actually in line with the research, there's not a ton of need to measure (for possible intervention probably), dev practice and testing
```{r}
ggplot(data,aes(Category,Unimportant,color=Category))+
  stat_summary(fun.data=mean_cl_boot)+
  ggtitle("Unimportant")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Unwise to measure

Don't measure productivity
```{r}
ggplot(data,aes(Category,Unwise,color=Category))+
  stat_summary(fun.data=mean_cl_boot)+
  theme_bw()+
  ggtitle("Unwise")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```