---
title: "Coding Bootcamps: What affects job placement and income?"
author: "Yim Register"
date: "8/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Learning to Code

https://github.com/freeCodeCamp/2016-new-coder-survey#about-the-data

This is a survey of over 15,000 respondants about their experiences of learning to code. You can read more about their goals, process, and survey [here](https://www.freecodecamp.org/news/we-just-launched-the-biggest-ever-survey-of-people-learning-to-code-cac81dadf1ea/#.8g9ts8gm5). The "Learn to Code!" buzz is not the same everywhere in the world, but it is clear that there is a need for these skills across almost every domain. But who is trying to learn? And who is failing? How might we intervene? You are a learner too, and it will be fun to compare your own answers to the survey as we go along. Today's lesson will be a warmup in R, Statistics, and handling data. 

## Topics Covered:

- data types
- data structure
- factors and outcomes
- measures of centrality
- bar plots
- normal distribution
- wilcox test
- kruskall wallis






## Load Your Libraries
```{r message=FALSE,warning=FALSE}
library(ggplot2)
library(dplyr)
library(kableExtra)

```

## Data Structure
```{r }
data <- read.csv("../data/newcoders.csv")
#head(data)

# how many people are in this dataset?
nrow(data)

# how many columns/questions?
ncol(data)

#this dataset is almost 50% NAs. It's not a problem, but something to be aware of
sum(!is.na(data))/sum(is.na(data))
```

## Useful Things To Do With Variables

```{r}

#get the data type
typeof(data$Age)

#get some descriptive statistics on the column
summary(data$Age)

#get the structure: datatype, range, and head
str(data$Age)

```

## Measures of Centrality
Mean, median, and mode
```{r message=FALSE, warning=FALSE}
#R doesn't have a built-in mode, but this means find the highest count for any of the values and return that value
getmode <- function(v) {
   uniqv <- unique(na.omit(v))
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

#mean, median, and mode

mean_age <-mean(data$Age,na.rm=TRUE)
med_age <- median(data$Age,na.rm=TRUE)
mode_age <-getmode(data$Age)

ggplot(data,aes(Age))+
  geom_histogram()+
  geom_vline(xintercept = mean_age,linetype="dashed",color="red")+
  geom_vline(xintercept = med_age,linetype="dashed",color="blue")+
  geom_vline(xintercept = mode_age,linetype="dashed",color="green")+
  theme_bw()


```

## Factors and Outcomes We Care About
When developing a research question, we often start with a vague idea of what you'd like to know about.

> "I want to know about people who learn to code in coding bootcamps"

The next steps involve questioning every inch of this idea until you have a fully formed, answerable research investigation. *What do you want to know? Any bootcamps? What people? What are they learning? Where? Do you want to know about their experience during or after?* There is **so much** to know, and this process can quickly become overwhelming. I remember during the first quarter of my PhD being so frustrated every time someone would poke at my barely formed research question, saying "yeah but what is *learning* exactly?"  This lesson will put into practice some of this "narrowing down" necessary to make progress. We might have a large dataset, with 15000 respondents and over 100 questions, but we will systematically choose our focus to make sense of a research question.By the end of the lesson, you may want to investigate something else in this dataset, and you'll have the tools to do that.

### Outcomes
Let's begin with identifying the **outcomes** we want to know about. These may also be referred to as **response variables** or **dependent variables**. They may also simply be represented by the variable **y**. So, we have a dataset of people who went through coding bootcamps. Maybe we want to know about their success in the bootcamp (whether they finished or not), their job prospects, and their income. We are also interested in their Employment field, which was answered categorically. 

Here we can see the summaries of the relevant outcome variables. Note that both `BootcampPostSalary` and `Income` (in the past year) were recorded. I'm assuming that these are different because maybe some people got salary boosts for participating in bootcamps, were offerred short contracting jobs, or other factors that made it so that it does not match up with the current Incomes at the time of the survey. More people answered about their Income, so we will use that measure primarily.

```{r}
summary(data$BootcampFinish)

summary(data$BootcampFullJobAfter)


summary(data$BootcampPostSalary)

summary(data$Income)

kable(summary(data$EmploymentField))%>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

### Factors
The **factors** are variables that may be affecting the outcomes we care about. These may also be referred to as **independent variables** or represented by the variable **x** (sometimes with numbered subscripts when there are multiple independent variables involved). Often these are demographics variables or things like time. Here, I select a few interesting factors: *Age, Gender, Money invested in the bootcamps, Education (including school major), Software development experience, and time spent practicing.*

```{r}
summary(data$Age)


summary(data$Gender)

summary(data$MoneyForLearning)

summary(data$MonthsProgramming)
summary(data$HoursLearning)

kable(summary(data$SchoolDegree))%>%
  kable_styling(bootstrap_options = c("striped", "hover"))

majors <- data[!is.na(data$SchoolMajor),] %>%
  count(SchoolMajor)%>%
  arrange(desc(n)) 
kable(head(majors,10))%>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```
## Descriptive vs. Inferential Statistics

A good place to start is working with the difference between descriptive and inferential statistics. **Descriptive** statistics are summmarizing and describing the data, without making conclusions about the larger population. This includes things like **measures of centrality, ranges, counts, spreads** and more. **Inferential** statistics uses the sample data to make conclusions about hypotheses regarding the general population that the sample may have come from. This includes **hypothesis testing** and **modeling**. Inferential statistics is also where you would see things like **effect size** and **significance (or p) values**. The way that I think about hypothesis testing is that we are looking for evidence for whether or not there is a *true difference* between groups. A *true difference* would mean a difference in the means or distributions that could reliably generalize if we got more people in the sample. We can never *prove* anything with statistics, but we can collect evidence. And that is powerful.

### Descriptive
We started looking at descriptive statistics when we used the `summary()` command in R. Another tool for descriptive statistics is data visualization and **histograms**. Below, we have a histogram for one of our outcome variables, `Income`
```{r fig.width=10, warning=FALSE}
ggplot(data,aes(Income))+
  geom_histogram(bins=40)+
  theme_bw()



```

Let's refer to one of our **factors** and take a look at a visualization of `Income`. I've selected `SchoolDegree` to see if the type of degree you have interacts with income in any way. What do you think?

```{r fig.width=10}
levels(data$SchoolDegree)

ggplot(data[!is.na(data$SchoolDegree),],aes(Income,fill=SchoolDegree))+
  geom_histogram(position="dodge")+
  theme_bw()

```

The above graph is a bit difficult to interpret. Instead, let's look at a more isolated comparison.  Let's isolate the groups we are curious about using `dplyr` and the `filter()` command in order to get a clearer visualization of those groups.

```{r fig.width=10}
ba_and_ma <- data %>%
                  filter(SchoolDegree %in% c("bachelor's degree", "master's degree (non-professional)","trade, technical, or vocational training"))


View(ba_and_ma)
ggplot(ba_and_ma,aes(Income,fill=SchoolDegree))+
  geom_histogram(position="dodge")+
  theme_bw()

```
At first, it's tempting to say that the groups differ by a lot, just by looking at the histogram. But this observation is almost entirely due to the fact that *much more* responders had Bachelor's degrees than any of the other `SchoolDegree` values. The histogram is showing raw counts, meaning that it's going to look very skewed towards the group with the largest population. We can barely even see the trade schoolers.

Let's take a look at a **normalized** histogram, and discuss what that means. Take a peek at the ballers over in the $200,000 income range. From the above histogram, we see that the raw count for those in that range is higher for those with Bachelor's degrees, and lowest for those with trade school experience.

```{r}
ba_and_ma$SchoolDegree <- droplevels(ba_and_ma$SchoolDegree)
kable(table(ba_and_ma$SchoolDegree[ba_and_ma$Income==200000]))%>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```
When we look at the *proportions*, maybe we have a different story. Is `.0085` (Bachelor's) really different from `.0083` (Master's)? Is `.0067` (trade school) really different? Or could it be the case that no matter what degree you started with, the coding bootcamps give you an equal opportunity for eventual Income?

The numbers confirm what we observed in the raw counts. The raw counts are not useless as we may want to know that more bootcampers had Bachelor's degrees and most of those in the $200,000 Income range had Bachelor's degrees (in this subset). But in comparing the *distributions*, we need the **proportions** instead.

```{r}
ba_and_ma <- ba_and_ma %>%
  group_by(SchoolDegree,Income) %>%
  summarise(n=n())%>%
  mutate(prop = n / sum(n))

#48/sum(ba_and_ma$n[ba_and_ma$SchoolDegree=="bachelor's degree"])



kable(na.omit(ba_and_ma[ba_and_ma$Income==200000,]))%>%
  kable_styling(bootstrap_options = c("striped", "hover"))


```

```{r}


plt=ggplot(ba_and_ma,aes(Income,fill=SchoolDegree))+
  geom_histogram(aes(y = stat(density)),position="dodge")+
  theme_bw()
plt

```

We might be able to use our common sense to determine that these two groups are, in fact, the same. But it is not always so clear. This is why we rely on statistical tests to *find evidence against the null hypothesis*. The **null hypothesis** can be thought of like the "devil's advocate" of the problem: Nothing is happening here, there is no difference, and you're wasting your time looking for one. With enough evidence, we can argue that the null hypothesis is full of BS.

### Inferential
Using our example from above, Bachelor's vs. Master's degree students and their `Income` values, let's look to see if we can find evidence that they are truly different phenomena. I've also included the trade schoolers, but we will get to that later.


> Null Hypothesis (H<sub>0</sub>): There is no true difference in Bootcamp Post Salary for those with Bachelor's degrees vs those with Master's degrees.
>
> Alternative Hypothesis (H<sub>A</sub>): There is a true difference in Bootcamp Post Salary for those with Bachelor's degree vs those with Master's degrees.

- Step 1: test the normality of the distributions you're working with
```{r}
ggplot(ba_and_ma[ba_and_ma$SchoolDegree=="bachelor's degree",],aes(Income))+
         geom_histogram(bins=40)+
  theme_bw()

ggplot(ba_and_ma[ba_and_ma$SchoolDegree=="master's degree (non-professional)",],aes(Income))+
         geom_histogram(bins=40)+
  theme_bw()

ggplot(ba_and_ma[ba_and_ma$SchoolDegree=="trade, technical, or vocational training",],aes(Income))+
         geom_histogram(bins=40)+
  theme_bw()

normals <- ba_and_ma %>%
  group_by(SchoolDegree) %>%
  summarise(normality =shapiro.test(Income)$statistic, 
p.value = shapiro.test(Income)$p.value) 

normals

```

```{r}
length(data$Income[data$SchoolDegree=="trade, technical, or vocational training"])
```